{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "04fa23da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading GPT-2 model and tokenizer...\n",
      "\n",
      "Generating for Direct Instruction prompt...\n",
      "Output 1: The key to academic success is to work in groups.\n",
      "Output 2: The key to academic success is to create strong relationships with students and teachers.\n",
      "Output 3: The key to academic success is finding ways to achieve it.\n",
      "\n",
      "Generating for Scenario-Based prompt...\n",
      "Output 1: When I failed my exam, my professor told me: \" That means you have to give your full name, your last name (the last syllable of your name), your first name and your second\n",
      "Output 2: When I failed my exam, my professor told me: \" You have got to do what is right.\n",
      "Output 3: When I failed my exam, my professor told me: \" You are the boss, now don't you think you can hold your nose?\"\n",
      "\n",
      "You have never been an American.\n",
      "\n",
      "Generating for Persona-Based prompt...\n",
      "Output 1: As a scientist who has experienced many failures, I believe that \"the answer is simple: if you are not doing something right, your performance will suffer.\"\n",
      "Output 2: As a scientist who has experienced many failures, I believe that \"my experience is far more than anecdotal.\"\n",
      "Output 3: As a scientist who has experienced many failures, I believe that \"the best way to overcome them is to avoid them.\"\n",
      "\n",
      "Generating for Persona-Based 2 prompt...\n",
      "Output 1: Einstein once said about persistence: \" \"There's a fundamental difference between persistence and persistence of a particular phenomenon.\"\n",
      "Output 2: Einstein once said about persistence: \" \"If you don't get out of it, you never get back.\"\n",
      "Output 3: Einstein once said about persistence: \" \"It's like you're just going to stop and think about it, and then you'll get it.\"\n",
      "\n",
      "Generating for Keyword-Based prompt...\n",
      "Output 1: Success comes to those who persist and learn because you are always there to give them a chance.\n",
      "Output 2: Success comes to those who persist and learn because of this simple principle:\n",
      "\n",
      "Do not lose.\n",
      "Output 3: Success comes to those who persist and learn because they believe that they can change the world, that their role is to contribute.\n",
      "\n",
      "Generating for Conversational prompt...\n",
      "Output 1: Student: I failed again.\n",
      "Mentor: Don't worry, remember that I have to go. Thank you very much. (To Muffles)\n",
      "Kamala: Are you okay?\n",
      "Erik: Yeah, thank you, but my neck is still sore. That's\n",
      "Output 2: Student: I failed again.\n",
      "Mentor: Don't worry, remember that we don't have a lawyer. We just ask that you go back and talk to us. You will be taken care of by our lawyer and we will take care about your situation. I don´t want to\n",
      "Output 3: Student: I failed again.\n",
      "Mentor: Don't worry, remember that I'm your father. [She is interrupted]\n",
      "F-Future's father: You didn't know my name?\n",
      "Future: It was an old name. I tried to write it down and then I got\n",
      "\n",
      "Human Reference:\n",
      "\"Success is not the absence of failure; it's the persistence through failure.\" - A.P.J. Abdul Kalam, former President of India and aerospace scientist [Source: 'Wings of Fire' autobiography]\n",
      "Calculating BERTScore...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 15.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 4.03 seconds, 4.46 sentences/sec\n",
      "\n",
      "Submission Checklist:\n",
      "\n",
      "1. The 5 prompts designed:\n",
      "   Direct Instruction: 'The key to academic success is'\n",
      "   Scenario-Based: 'When I failed my exam, my professor told me: \"'\n",
      "   Persona-Based: 'As a scientist who has experienced many failures, I believe that'\n",
      "   Persona-Based 2: 'Einstein once said about persistence: \"'\n",
      "   Keyword-Based: 'Success comes to those who persist and learn because'\n",
      "   Conversational: 'Student: I failed again.\n",
      "Mentor: Don't worry, remember that'\n",
      "\n",
      "2. All 15 GPT-2 outputs (3 per prompt):\n",
      "\n",
      "   Direct Instruction:\n",
      "      Output 1: The key to academic success is to work in groups.\n",
      "      Output 2: The key to academic success is to create strong relationships with students and teachers.\n",
      "      Output 3: The key to academic success is finding ways to achieve it.\n",
      "\n",
      "   Scenario-Based:\n",
      "      Output 1: When I failed my exam, my professor told me: \" That means you have to give your full name, your last name (the last syllable of your name), your first name and your second\n",
      "      Output 2: When I failed my exam, my professor told me: \" You have got to do what is right.\n",
      "      Output 3: When I failed my exam, my professor told me: \" You are the boss, now don't you think you can hold your nose?\"\n",
      "\n",
      "You have never been an American.\n",
      "\n",
      "   Persona-Based:\n",
      "      Output 1: As a scientist who has experienced many failures, I believe that \"the answer is simple: if you are not doing something right, your performance will suffer.\"\n",
      "      Output 2: As a scientist who has experienced many failures, I believe that \"my experience is far more than anecdotal.\"\n",
      "      Output 3: As a scientist who has experienced many failures, I believe that \"the best way to overcome them is to avoid them.\"\n",
      "\n",
      "   Persona-Based 2:\n",
      "      Output 1: Einstein once said about persistence: \" \"There's a fundamental difference between persistence and persistence of a particular phenomenon.\"\n",
      "      Output 2: Einstein once said about persistence: \" \"If you don't get out of it, you never get back.\"\n",
      "      Output 3: Einstein once said about persistence: \" \"It's like you're just going to stop and think about it, and then you'll get it.\"\n",
      "\n",
      "   Keyword-Based:\n",
      "      Output 1: Success comes to those who persist and learn because you are always there to give them a chance.\n",
      "      Output 2: Success comes to those who persist and learn because of this simple principle:\n",
      "\n",
      "Do not lose.\n",
      "      Output 3: Success comes to those who persist and learn because they believe that they can change the world, that their role is to contribute.\n",
      "\n",
      "   Conversational:\n",
      "      Output 1: Student: I failed again.\n",
      "Mentor: Don't worry, remember that I have to go. Thank you very much. (To Muffles)\n",
      "Kamala: Are you okay?\n",
      "Erik: Yeah, thank you, but my neck is still sore. That's\n",
      "      Output 2: Student: I failed again.\n",
      "Mentor: Don't worry, remember that we don't have a lawyer. We just ask that you go back and talk to us. You will be taken care of by our lawyer and we will take care about your situation. I don´t want to\n",
      "      Output 3: Student: I failed again.\n",
      "Mentor: Don't worry, remember that I'm your father. [She is interrupted]\n",
      "F-Future's father: You didn't know my name?\n",
      "Future: It was an old name. I tried to write it down and then I got\n",
      "\n",
      "3. Human-written reference:\n",
      "   \"Success is not the absence of failure; it's the persistence through failure.\" - A.P.J. Abdul Kalam, former President of India and aerospace scientist [Source: 'Wings of Fire' autobiography]\n",
      "\n",
      "4. BERTScore output table:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prompt Type</th>\n",
       "      <th>Output #</th>\n",
       "      <th>BERTScore F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Direct Instruction</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Direct Instruction</td>\n",
       "      <td>2</td>\n",
       "      <td>0.8421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Direct Instruction</td>\n",
       "      <td>3</td>\n",
       "      <td>0.8481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Scenario-Based</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Scenario-Based</td>\n",
       "      <td>2</td>\n",
       "      <td>0.8366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Scenario-Based</td>\n",
       "      <td>3</td>\n",
       "      <td>0.8222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Persona-Based</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Persona-Based</td>\n",
       "      <td>2</td>\n",
       "      <td>0.8363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Persona-Based</td>\n",
       "      <td>3</td>\n",
       "      <td>0.8534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Persona-Based 2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Persona-Based 2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.8404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Persona-Based 2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.8378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Keyword-Based</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Keyword-Based</td>\n",
       "      <td>2</td>\n",
       "      <td>0.8271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Keyword-Based</td>\n",
       "      <td>3</td>\n",
       "      <td>0.8387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Conversational</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Conversational</td>\n",
       "      <td>2</td>\n",
       "      <td>0.8097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Conversational</td>\n",
       "      <td>3</td>\n",
       "      <td>0.8098</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Prompt Type  Output #  BERTScore F1\n",
       "0   Direct Instruction         1        0.8532\n",
       "1   Direct Instruction         2        0.8421\n",
       "2   Direct Instruction         3        0.8481\n",
       "3       Scenario-Based         1        0.8052\n",
       "4       Scenario-Based         2        0.8366\n",
       "5       Scenario-Based         3        0.8222\n",
       "6        Persona-Based         1        0.8448\n",
       "7        Persona-Based         2        0.8363\n",
       "8        Persona-Based         3        0.8534\n",
       "9      Persona-Based 2         1        0.8463\n",
       "10     Persona-Based 2         2        0.8404\n",
       "11     Persona-Based 2         3        0.8378\n",
       "12       Keyword-Based         1        0.8343\n",
       "13       Keyword-Based         2        0.8271\n",
       "14       Keyword-Based         3        0.8387\n",
       "15      Conversational         1        0.8095\n",
       "16      Conversational         2        0.8097\n",
       "17      Conversational         3        0.8098"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary Statistics by Prompt Type:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prompt Type</th>\n",
       "      <th>Average F1</th>\n",
       "      <th>Min F1</th>\n",
       "      <th>Max F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Direct Instruction</td>\n",
       "      <td>0.8478</td>\n",
       "      <td>0.8421</td>\n",
       "      <td>0.8532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Persona-Based</td>\n",
       "      <td>0.8448</td>\n",
       "      <td>0.8363</td>\n",
       "      <td>0.8534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Persona-Based 2</td>\n",
       "      <td>0.8415</td>\n",
       "      <td>0.8378</td>\n",
       "      <td>0.8463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Keyword-Based</td>\n",
       "      <td>0.8334</td>\n",
       "      <td>0.8271</td>\n",
       "      <td>0.8387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Scenario-Based</td>\n",
       "      <td>0.8213</td>\n",
       "      <td>0.8052</td>\n",
       "      <td>0.8366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Conversational</td>\n",
       "      <td>0.8097</td>\n",
       "      <td>0.8095</td>\n",
       "      <td>0.8098</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Prompt Type  Average F1  Min F1  Max F1\n",
       "1  Direct Instruction      0.8478  0.8421  0.8532\n",
       "3       Persona-Based      0.8448  0.8363  0.8534\n",
       "4     Persona-Based 2      0.8415  0.8378  0.8463\n",
       "2       Keyword-Based      0.8334  0.8271  0.8387\n",
       "5      Scenario-Based      0.8213  0.8052  0.8366\n",
       "0      Conversational      0.8097  0.8095  0.8098"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Detailed Outputs with Scores:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prompt Type</th>\n",
       "      <th>Output #</th>\n",
       "      <th>BERTScore F1</th>\n",
       "      <th>Output Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Direct Instruction</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8532</td>\n",
       "      <td>The key to academic success is to work in groups.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Direct Instruction</td>\n",
       "      <td>2</td>\n",
       "      <td>0.8421</td>\n",
       "      <td>The key to academic success is to create stron...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Direct Instruction</td>\n",
       "      <td>3</td>\n",
       "      <td>0.8481</td>\n",
       "      <td>The key to academic success is finding ways to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Scenario-Based</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8052</td>\n",
       "      <td>When I failed my exam, my professor told me: \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Scenario-Based</td>\n",
       "      <td>2</td>\n",
       "      <td>0.8366</td>\n",
       "      <td>When I failed my exam, my professor told me: \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Scenario-Based</td>\n",
       "      <td>3</td>\n",
       "      <td>0.8222</td>\n",
       "      <td>When I failed my exam, my professor told me: \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Persona-Based</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8448</td>\n",
       "      <td>As a scientist who has experienced many failur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Persona-Based</td>\n",
       "      <td>2</td>\n",
       "      <td>0.8363</td>\n",
       "      <td>As a scientist who has experienced many failur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Persona-Based</td>\n",
       "      <td>3</td>\n",
       "      <td>0.8534</td>\n",
       "      <td>As a scientist who has experienced many failur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Persona-Based 2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8463</td>\n",
       "      <td>Einstein once said about persistence: \" \"There...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Persona-Based 2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.8404</td>\n",
       "      <td>Einstein once said about persistence: \" \"If yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Persona-Based 2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.8378</td>\n",
       "      <td>Einstein once said about persistence: \" \"It's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Keyword-Based</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8343</td>\n",
       "      <td>Success comes to those who persist and learn b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Keyword-Based</td>\n",
       "      <td>2</td>\n",
       "      <td>0.8271</td>\n",
       "      <td>Success comes to those who persist and learn b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Keyword-Based</td>\n",
       "      <td>3</td>\n",
       "      <td>0.8387</td>\n",
       "      <td>Success comes to those who persist and learn b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Conversational</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8095</td>\n",
       "      <td>Student: I failed again.\\nMentor: Don't worry,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Conversational</td>\n",
       "      <td>2</td>\n",
       "      <td>0.8097</td>\n",
       "      <td>Student: I failed again.\\nMentor: Don't worry,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Conversational</td>\n",
       "      <td>3</td>\n",
       "      <td>0.8098</td>\n",
       "      <td>Student: I failed again.\\nMentor: Don't worry,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Prompt Type  Output #  BERTScore F1  \\\n",
       "0   Direct Instruction         1        0.8532   \n",
       "1   Direct Instruction         2        0.8421   \n",
       "2   Direct Instruction         3        0.8481   \n",
       "3       Scenario-Based         1        0.8052   \n",
       "4       Scenario-Based         2        0.8366   \n",
       "5       Scenario-Based         3        0.8222   \n",
       "6        Persona-Based         1        0.8448   \n",
       "7        Persona-Based         2        0.8363   \n",
       "8        Persona-Based         3        0.8534   \n",
       "9      Persona-Based 2         1        0.8463   \n",
       "10     Persona-Based 2         2        0.8404   \n",
       "11     Persona-Based 2         3        0.8378   \n",
       "12       Keyword-Based         1        0.8343   \n",
       "13       Keyword-Based         2        0.8271   \n",
       "14       Keyword-Based         3        0.8387   \n",
       "15      Conversational         1        0.8095   \n",
       "16      Conversational         2        0.8097   \n",
       "17      Conversational         3        0.8098   \n",
       "\n",
       "                                          Output Text  \n",
       "0   The key to academic success is to work in groups.  \n",
       "1   The key to academic success is to create stron...  \n",
       "2   The key to academic success is finding ways to...  \n",
       "3   When I failed my exam, my professor told me: \"...  \n",
       "4   When I failed my exam, my professor told me: \"...  \n",
       "5   When I failed my exam, my professor told me: \"...  \n",
       "6   As a scientist who has experienced many failur...  \n",
       "7   As a scientist who has experienced many failur...  \n",
       "8   As a scientist who has experienced many failur...  \n",
       "9   Einstein once said about persistence: \" \"There...  \n",
       "10  Einstein once said about persistence: \" \"If yo...  \n",
       "11  Einstein once said about persistence: \" \"It's ...  \n",
       "12  Success comes to those who persist and learn b...  \n",
       "13  Success comes to those who persist and learn b...  \n",
       "14  Success comes to those who persist and learn b...  \n",
       "15  Student: I failed again.\\nMentor: Don't worry,...  \n",
       "16  Student: I failed again.\\nMentor: Don't worry,...  \n",
       "17  Student: I failed again.\\nMentor: Don't worry,...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Visualization saved as 'bertscore_by_prompt_type.png'\n",
      "\n",
      "Saving results to Excel...\n",
      "\n",
      "Results saved to 'gpt2_prompt_results.xlsx' with proper formatting\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "from bert_score import score\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "def setup_gpt2():\n",
    "    \"\"\"Load the GPT-2 model and tokenizer\"\"\"\n",
    "    print(\"Loading GPT-2 model and tokenizer...\")\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "    model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    return model, tokenizer\n",
    "\n",
    "def generate_text(prompt, model, tokenizer, max_length=40, num_return=3, \n",
    "                 temperature=0.9, top_k=50, top_p=0.95):\n",
    "    \"\"\"Generate text from a prompt using GPT-2\n",
    "    - Using text completion approach rather than instruction following\n",
    "    - Shorter max_length (40) since we only need to generate the completion\n",
    "    - Higher temperature (0.9) for creative completions\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(prompt, return_tensors='pt', padding=True)\n",
    "    \n",
    "    # Generate outputs\n",
    "    outputs = model.generate(\n",
    "        input_ids=inputs['input_ids'],\n",
    "        attention_mask=inputs['attention_mask'],\n",
    "        max_length=max_length,\n",
    "        num_return_sequences=num_return,\n",
    "        do_sample=True,\n",
    "        top_k=top_k,\n",
    "        top_p=top_p,\n",
    "        temperature=temperature,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        no_repeat_ngram_size=2  # Prevent repetition of n-grams\n",
    "    )\n",
    "    \n",
    "    # Decode and return the generated texts\n",
    "    return [tokenizer.decode(output, skip_special_tokens=True) for output in outputs]\n",
    "\n",
    "def define_prompts():\n",
    "    \"\"\"Define different prompt types for the experiment - formatted for GPT-2 completion style\"\"\"\n",
    "    return {\n",
    "        # For GPT-2, use partial statements it can complete rather than instructions\n",
    "        \"Direct Instruction\": \"The key to academic success is\",\n",
    "        \"Scenario-Based\": \"When I failed my exam, my professor told me: \\\"\",\n",
    "        \"Persona-Based\": \"As a scientist who has experienced many failures, I believe that\",\n",
    "        # More persona variations that worked well\n",
    "        \"Persona-Based 2\": \"Einstein once said about persistence: \\\"\",\n",
    "        \"Keyword-Based\": \"Success comes to those who persist and learn because\",\n",
    "        \"Conversational\": \"Student: I failed again.\\nMentor: Don't worry, remember that\"\n",
    "    }\n",
    "\n",
    "def get_human_reference():\n",
    "    \"\"\"Return the human-written reference quote\"\"\"\n",
    "    return '\"Success is not the absence of failure; it\\'s the persistence through failure.\" - A.P.J. Abdul Kalam, former President of India and aerospace scientist [Source: \\'Wings of Fire\\' autobiography]'\n",
    "\n",
    "def process_outputs(outputs, prompts=None, prompt_type=None):\n",
    "    \"\"\"Process outputs to clean up and ensure they're motivational\n",
    "    Added handling for prompt prefix removal and sentence completion\n",
    "    \"\"\"\n",
    "    processed = []\n",
    "    \n",
    "    # Get the current prompt if provided\n",
    "    current_prompt = None\n",
    "    if prompts and prompt_type:\n",
    "        current_prompt = prompts[prompt_type]\n",
    "    \n",
    "    for output in outputs:\n",
    "        # First remove the prompt to get just the generated content\n",
    "        if current_prompt and output.startswith(current_prompt):\n",
    "            output = output[len(current_prompt):].strip()\n",
    "        \n",
    "        # Special handling for conversational outputs - avoid truncation\n",
    "        if prompt_type == \"Conversational\":\n",
    "            # Format the output properly to avoid truncation\n",
    "            mentor_response = output.split(\"Mentor: Don't worry, remember that\")[1].strip() if \"Mentor: Don't worry, remember that\" in output else output\n",
    "            full_output = f\"Student: I failed again.\\nMentor: Don't worry, remember that {mentor_response}\"\n",
    "            processed.append(full_output)\n",
    "            continue\n",
    "            \n",
    "        # Truncate at sentence end if possible\n",
    "        end_markers = ['.', '!', '?', '\"', '\\n']\n",
    "        for marker in end_markers:\n",
    "            pos = output.find(marker)\n",
    "            if pos > 5:  # Ensure we have some content\n",
    "                output = output[:pos+1]\n",
    "                break\n",
    "                \n",
    "        # Clean up other issues\n",
    "        output = output.strip(',\" \\n')\n",
    "        \n",
    "        # Add quotes for persona outputs if needed\n",
    "        if prompt_type and \"Persona-Based\" in prompt_type and not output.startswith('\"'):\n",
    "            output = f'\"{output}\"'\n",
    "            \n",
    "        # Add the prompt back for context\n",
    "        if current_prompt:\n",
    "            full_output = f\"{current_prompt} {output}\"\n",
    "        else:\n",
    "            full_output = output\n",
    "            \n",
    "        processed.append(full_output)\n",
    "    \n",
    "    return processed\n",
    "\n",
    "def evaluate_with_bertscore(all_outputs, reference):\n",
    "    \"\"\"Evaluate outputs using BERTScore against reference\"\"\"\n",
    "    print(\"Calculating BERTScore...\")\n",
    "    P, R, F1 = score(all_outputs, [reference] * len(all_outputs), lang='en', verbose=True)\n",
    "    return P, R, F1\n",
    "\n",
    "def visualize_results(results_df):\n",
    "    \"\"\"Create visualizations for the results\"\"\"\n",
    "    # Group and aggregate BERTScore F1 by prompt type\n",
    "    agg_results = results_df.groupby('Prompt Type', as_index=False)['BERTScore F1'].mean()\n",
    "\n",
    "    # Plot using seaborn, with hue to avoid warning\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(\n",
    "        data=agg_results,\n",
    "        x='Prompt Type',\n",
    "        y='BERTScore F1',\n",
    "        hue='Prompt Type',\n",
    "        palette='muted',\n",
    "        legend=False  # hide redundant legend\n",
    "    )\n",
    "    plt.title('Average BERTScore F1 by Prompt Type')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('bertscore_by_prompt_type.png')\n",
    "    plt.close()\n",
    "\n",
    "    return plt.gcf()\n",
    "\n",
    "\n",
    "\n",
    "def create_results_table(gpt2_outputs, F1):\n",
    "    \"\"\"Create dataframe with results\"\"\"\n",
    "    results = []\n",
    "    idx = 0\n",
    "    for prompt_type in gpt2_outputs:\n",
    "        for i in range(len(gpt2_outputs[prompt_type])):\n",
    "            results.append({\n",
    "                \"Prompt Type\": prompt_type,\n",
    "                \"Output #\": i+1,\n",
    "                \"BERTScore F1\": round(F1[idx].item(), 4),\n",
    "                \"Output Text\": gpt2_outputs[prompt_type][i]\n",
    "            })\n",
    "            idx += 1\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "def generate_summary_stats(results_df):\n",
    "    \"\"\"Generate summary statistics for each prompt type\"\"\"\n",
    "    summary = results_df.groupby('Prompt Type')['BERTScore F1'].agg(\n",
    "        ['mean', 'min', 'max']).round(4).reset_index()\n",
    "    summary.columns = ['Prompt Type', 'Average F1', 'Min F1', 'Max F1']\n",
    "    summary = summary.sort_values('Average F1', ascending=False)\n",
    "    return summary\n",
    "\n",
    "def print_submission_checklist(prompts, gpt2_outputs, human_reference):\n",
    "    \"\"\"Print the submission checklist in the required format\"\"\"\n",
    "    print(\"\\nSubmission Checklist:\\n\")\n",
    "    print(\"1. The 5 prompts designed:\")\n",
    "    for prompt_type, prompt in prompts.items():\n",
    "        print(f\"   {prompt_type}: '{prompt}'\")\n",
    "    \n",
    "    print(\"\\n2. All 15 GPT-2 outputs (3 per prompt):\")\n",
    "    for prompt_type in gpt2_outputs:\n",
    "        print(f\"\\n   {prompt_type}:\")\n",
    "        for i, output in enumerate(gpt2_outputs[prompt_type], 1):\n",
    "            print(f\"      Output {i}: {output}\")\n",
    "    \n",
    "    print(\"\\n3. Human-written reference:\")\n",
    "    print(f\"   {human_reference}\")\n",
    "\n",
    "def main():\n",
    "    # Part 1: Load GPT-2 Model\n",
    "    model, tokenizer = setup_gpt2()\n",
    "    \n",
    "    # Part 2: Design Prompts and Generate Outputs\n",
    "    prompts = define_prompts()\n",
    "    \n",
    "    # Generate outputs with varied parameters for different prompt types\n",
    "    gpt2_outputs = {}\n",
    "    for prompt_type, prompt in prompts.items():\n",
    "        print(f\"\\nGenerating for {prompt_type} prompt...\")\n",
    "        \n",
    "        # Customize parameters based on prompt type\n",
    "        if \"Persona-Based\" in prompt_type:\n",
    "            temp = 0.85\n",
    "            max_len = 50  # Slightly longer for persona-based\n",
    "        elif prompt_type == \"Direct Instruction\":\n",
    "            temp = 0.8\n",
    "            max_len = 30  # Short completions for direct style\n",
    "        elif prompt_type == \"Conversational\":\n",
    "            temp = 0.9\n",
    "            max_len = 60  # Longer for conversational to capture full response\n",
    "        else:\n",
    "            temp = 0.9\n",
    "            max_len = 40\n",
    "            \n",
    "        outputs = generate_text(\n",
    "            prompt, \n",
    "            model, \n",
    "            tokenizer,\n",
    "            max_length=max_len,\n",
    "            num_return=3,\n",
    "            temperature=temp\n",
    "        )\n",
    "        \n",
    "        # Process outputs with knowledge of prompt context\n",
    "        gpt2_outputs[prompt_type] = process_outputs(outputs, prompts, prompt_type)\n",
    "        \n",
    "        for i, output in enumerate(gpt2_outputs[prompt_type], 1):\n",
    "            print(f\"Output {i}: {output}\")\n",
    "    \n",
    "    # Part 3: Get Human Reference\n",
    "    human_reference = get_human_reference()\n",
    "    print(\"\\nHuman Reference:\")\n",
    "    print(human_reference)\n",
    "    \n",
    "    # Part 4: Evaluate Outputs Using BERTScore\n",
    "    # Flatten outputs for evaluation\n",
    "    all_outputs = []\n",
    "    for prompt_type in gpt2_outputs:\n",
    "        all_outputs.extend(gpt2_outputs[prompt_type])\n",
    "    \n",
    "    # Calculate BERTScore\n",
    "    P, R, F1 = evaluate_with_bertscore(all_outputs, human_reference)\n",
    "    \n",
    "    # Part 5: Create Results Table\n",
    "    results_df = create_results_table(gpt2_outputs, F1)\n",
    "    \n",
    "    # Generate summary statistics\n",
    "    summary_stats = generate_summary_stats(results_df)\n",
    "    \n",
    "    # Print submission checklist\n",
    "    print_submission_checklist(prompts, gpt2_outputs, human_reference)\n",
    "    \n",
    "    # Display results\n",
    "    print(\"\\n4. BERTScore output table:\")\n",
    "    display(results_df[[\"Prompt Type\", \"Output #\", \"BERTScore F1\"]])\n",
    "    \n",
    "    print(\"\\nSummary Statistics by Prompt Type:\")\n",
    "    display(summary_stats)\n",
    "    \n",
    "    print(\"\\nDetailed Outputs with Scores:\")\n",
    "    display(results_df[[\"Prompt Type\", \"Output #\", \"BERTScore F1\", \"Output Text\"]])\n",
    "    \n",
    "    # Create visualization\n",
    "    try:\n",
    "        fig = visualize_results(results_df)\n",
    "        plt.close(fig)\n",
    "        print(\"\\nVisualization saved as 'bertscore_by_prompt_type.png'\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not create visualization: {e}\")\n",
    "    \n",
    "    # Save results directly to Excel with proper formatting\n",
    "    print(\"\\nSaving results to Excel...\")\n",
    "    excel_writer = pd.ExcelWriter('gpt2_prompt_results.xlsx', engine='openpyxl')\n",
    "    results_df.to_excel(excel_writer, index=False, sheet_name='Results')\n",
    "    \n",
    "    # Adjust column widths for better readability in Excel\n",
    "    worksheet = excel_writer.sheets['Results']\n",
    "    worksheet.column_dimensions['A'].width = 20  # Prompt Type\n",
    "    worksheet.column_dimensions['B'].width = 10  # Output #\n",
    "    worksheet.column_dimensions['C'].width = 15  # BERTScore\n",
    "    worksheet.column_dimensions['D'].width = 100  # Output Text\n",
    "    \n",
    "    excel_writer.close()\n",
    "    print(\"\\nResults saved to 'gpt2_prompt_results.xlsx' with proper formatting\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
